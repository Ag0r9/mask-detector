{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# First face mask prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = 'data/Medical mask/Medical mask/Medical Mask/annotations'\n",
    "image_directory = 'data/Medical mask/Medical mask/Medical Mask/images'\n",
    "df = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvNet = cv2.dnn.readNetFromCaffe('data/face-detector-model/architecture.txt',\n",
    "                                 'data/face-detector-model/weights.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJSON(filePathandName):\n",
    "    with open(filePathandName,'r') as f:\n",
    "        return json.load(f)\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)])\n",
    "    return cv2.LUT(image.astype(np.uint8), table.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FileName': '1801.jpg',\n",
       " 'NumOfAnno': 1,\n",
       " 'Annotations': [{'isProtected': False,\n",
       "   'ID': 924868908868875136,\n",
       "   'BoundingBox': [451, 186, 895, 697],\n",
       "   'classname': 'face_no_mask',\n",
       "   'Confidence': 1,\n",
       "   'Attributes': {}}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonfiles= []\n",
    "for i in os.listdir(json_file_path):\n",
    "    jsonfiles.append(getJSON(os.path.join(json_file_path,i)))\n",
    "jsonfiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>classname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>69</td>\n",
       "      <td>126</td>\n",
       "      <td>294</td>\n",
       "      <td>392</td>\n",
       "      <td>face_with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>505</td>\n",
       "      <td>10</td>\n",
       "      <td>723</td>\n",
       "      <td>283</td>\n",
       "      <td>face_with_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>75</td>\n",
       "      <td>252</td>\n",
       "      <td>264</td>\n",
       "      <td>390</td>\n",
       "      <td>mask_colorful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2756.png</td>\n",
       "      <td>521</td>\n",
       "      <td>136</td>\n",
       "      <td>711</td>\n",
       "      <td>277</td>\n",
       "      <td>mask_colorful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6098.jpg</td>\n",
       "      <td>360</td>\n",
       "      <td>85</td>\n",
       "      <td>728</td>\n",
       "      <td>653</td>\n",
       "      <td>face_no_mask</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name   x1   x2   y1   y2       classname\n",
       "0  2756.png   69  126  294  392  face_with_mask\n",
       "1  2756.png  505   10  723  283  face_with_mask\n",
       "2  2756.png   75  252  264  390   mask_colorful\n",
       "3  2756.png  521  136  711  277   mask_colorful\n",
       "4  6098.jpg  360   85  728  653    face_no_mask"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['face_with_mask', 'mask_colorful', 'face_no_mask',\n",
       "       'face_with_mask_incorrect', 'mask_surgical', 'face_other_covering',\n",
       "       'scarf_bandana', 'eyeglasses', 'helmet', 'face_shield',\n",
       "       'sunglasses', 'hood', 'hat', 'goggles', 'hair_net', 'hijab_niqab',\n",
       "       'other', 'gas_mask', 'balaclava_ski_mask', 'turban'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(df.classname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_classnames = ['face_with_mask', 'face_no_mask']\n",
    "df_selected = df.loc[df.classname.isin(selected_classnames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_selected.classname.value_counts().plot(kind='barh', rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4326/4326 [02:46<00:00, 25.91it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "img_size = 124\n",
    "mask = ['face_with_mask']\n",
    "non_mask = ['face_no_mask']\n",
    "labels={'face_with_mask':0,'face_no_mask':1}\n",
    "for picture_name in tqdm(df['name'].unique()):\n",
    "    file = f'{picture_name}.json'\n",
    "    for j in getJSON(os.path.join(json_file_path,file)).get('Annotations'):\n",
    "        if j['classname'] in mask:\n",
    "            x,y,w,h = j['BoundingBox']\n",
    "            img = cv2.imread(os.path.join(image_directory, picture_name),1)\n",
    "            img = img[y:h,x:w]\n",
    "            img = cv2.resize(img,(img_size,img_size))\n",
    "            data.append([img,labels['face_with_mask']])\n",
    "        if j['classname'] in non_mask:\n",
    "            x,y,w,h = j['BoundingBox']\n",
    "            img = cv2.imread(os.path.join(image_directory, picture_name),1)\n",
    "            img = img[y:h,x:w]\n",
    "            img = cv2.resize(img,(img_size,img_size))    \n",
    "            data.append([img,labels['face_no_mask']])\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for features,label in data:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "\n",
    "X = np.array(X)/255.0\n",
    "X = X.reshape(-1,124,124,3)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp/ipykernel_14944/3563897778.py:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(datagen.flow(xtrain, ytrain, batch_size=32),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "124/144 [========================>.....] - ETA: 1:09 - loss: 0.4526 - accuracy: 0.8237"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding = \"same\", activation='relu', input_shape=(124,124,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam' ,metrics=['accuracy'])\n",
    "xtrain,xval,ytrain,yval=train_test_split(X, Y,train_size=0.8,random_state=0)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,  \n",
    "        samplewise_std_normalization=False,  \n",
    "        zca_whitening=False,    \n",
    "        rotation_range=15,    \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,  \n",
    "        horizontal_flip=True,  \n",
    "        vertical_flip=False)\n",
    "\n",
    "datagen.fit(xtrain)\n",
    "\n",
    "history = model.fit_generator(datagen.flow(xtrain, ytrain, batch_size=32),\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(xval, yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],'g')\n",
    "plt.plot(history.history['val_accuracy'],'b')\n",
    "plt.title('Training Accuracy vs Validation Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],'g')\n",
    "plt.plot(history.history['val_loss'],'b')\n",
    "plt.title('Training Loss vs Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"data/Mask_Detection_Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = ['2756.png','5342.jpg', '4591.png','3939.png','3939.png','3911.png']\n",
    "\n",
    "gamma = 2.0\n",
    "fig = plt.figure(figsize = (14,14))\n",
    "rows = 3\n",
    "cols = 2\n",
    "axes = []\n",
    "assign = {'0':'Mask','1':\"No Mask\"}\n",
    "for j,im in enumerate(test_images):\n",
    "    image =  cv2.imread(os.path.join(image_directory,im),1)\n",
    "    image =  adjust_gamma(image, gamma=gamma)\n",
    "    (h, w) = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300,300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    cvNet.setInput(blob)\n",
    "    detections = cvNet.forward()\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        try:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            frame = image[startY:endY, startX:endX]\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.2:\n",
    "                im = cv2.resize(frame,(img_size,img_size))\n",
    "                im = np.array(im)/255.0\n",
    "                im = im.reshape(1,124,124,3)\n",
    "                result = model.predict(im)\n",
    "                if result>0.5:\n",
    "                    label_Y = 1\n",
    "                else:\n",
    "                    label_Y = 0\n",
    "                cv2.rectangle(image, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "                cv2.putText(image,assign[str(label_Y)] , (startX, startY-10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (36,255,12), 2)\n",
    "        \n",
    "        except:pass\n",
    "    axes.append(fig.add_subplot(rows, cols, j+1))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (projekt)",
   "language": "python",
   "name": "pycharm-d5a17d9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
